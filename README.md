# ğŸ¤ Voice-First AI Assistant

A sophisticated voice-enabled AI assistant featuring real-time streaming responses, intelligent interrupt handling, and persistent conversation memory.

## âœ¨ Key Features

### 1. **Streaming Intelligence**
- Token-by-token LLM responses (Claude Sonnet 4)
- Real-time text-to-speech synthesis
- No waiting for complete responses

### 2. **Smart Interruption**
- Interrupt mid-sentence by speaking
- Assistant stops immediately
- Context preserved for follow-up

### 3. **Conversation Memory**
- **Short-term buffer**: Recent 10 messages in full detail
- **Long-term context**: Summarized older conversations
- Persistent memory across sessions
- Remembers context from previous days

### 4. **Push-to-Talk Interface**
- Hold SPACE to speak
- Release to process
- Natural conversation flow

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Microphone â”‚â”€â”€â”€â”€â–¶â”‚ Whisper STT  â”‚â”€â”€â”€â”€â–¶â”‚   Claude    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   Sonnet    â”‚
                                          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚   Speaker   â”‚â—€â”€â”€â”€â”€â”‚  OpenAI TTS  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚    Conversation Memory        â”‚
       â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
       â”‚  â”‚  Short-term (10 msgs)   â”‚  â”‚
       â”‚  â”‚  + timestamps, full text  â”‚  â”‚
       â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
       â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
       â”‚  â”‚  Long-term (summaries)  â”‚  â”‚
       â”‚  â”‚  + persistent storage   â”‚  â”‚
       â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- Microphone and speakers
- Anthropic API key
- OpenAI API key

### Installation

1. **Clone or download the project**

2. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Run the setup wizard** (recommended):
   ```bash
   python setup_assistant.py
   ```
   
   Or manually create `.env` file:
   ```bash
   cp .env.example .env
   # Edit .env with your API keys
   ```

4. **Run the assistant**:
   ```bash
   python main.py
   ```

## ğŸ® Controls

| Key | Action |
|-----|--------|
| `SPACE` (hold) | Start recording your voice |
| `SPACE` (release) | Stop recording and process |
| `ESC` | Exit the assistant |
| Say "goodbye" | End conversation |

## ğŸ“‹ How It Works

### Conversation Flow

1. **User speaks** â†’ Hold SPACE
2. **Audio captured** â†’ Release SPACE
3. **Whisper transcription** â†’ Fast and accurate
4. **Context building** â†’ Adds to memory
5. **Claude processes** â†’ Streaming response
6. **TTS synthesis** â†’ Sentence-by-sentence
7. **Audio playback** â†’ Real-time output

### Interruption Flow

1. **Assistant speaking** â†’ Audio playing
2. **User presses SPACE** â†’ Playback stops immediately
3. **User speaks** â†’ New input captured
4. **Context preserved** â†’ Continues conversation naturally

### Memory Management

**Short-term Memory (10 messages)**:
- Stores recent conversation in full detail
- Includes timestamps
- Used for immediate context

**Long-term Memory (Summaries)**:
- Automatically summarizes after 20 messages
- Keeps last 500 words of context
- Persists across sessions
- Stored in `conversation_memory.json`

## ğŸ”§ Configuration

Edit `config.py` to customize:

```python
# LLM Settings
LLM_MODEL = "claude-sonnet-4-20250514"
MAX_TOKENS = 1000
TEMPERATURE = 0.7

# TTS Voice Options
TTS_VOICE = "alloy"  # alloy, echo, fable, onyx, nova, shimmer

# Memory Settings
SHORT_TERM_MEMORY_SIZE = 10
LONG_TERM_SUMMARY_THRESHOLD = 20
```

## ğŸ“ Project Structure

```
Voice-First AI Assistant/
â”œâ”€â”€ main.py                 # Main orchestrator
â”œâ”€â”€ config.py              # Configuration
â”œâ”€â”€ setup_assistant.py     # Setup wizard
â”‚
â”œâ”€â”€ audio/                 # Audio I/O
â”‚   â”œâ”€â”€ __init__.py       # AudioInput class
â”‚   â””â”€â”€ output.py         # AudioOutput class
â”‚
â”œâ”€â”€ speech/               # Speech processing
â”‚   â”œâ”€â”€ stt.py           # Whisper integration
â”‚   â””â”€â”€ tts.py           # OpenAI TTS
â”‚
â”œâ”€â”€ llm/                  # LLM integration
â”‚   â””â”€â”€ handler.py       # Claude streaming
â”‚
â”œâ”€â”€ memory/              # Memory management
â”‚   â””â”€â”€ manager.py       # Conversation memory
â”‚
â””â”€â”€ tests/               # Test suite
    â””â”€â”€ test_memory.py
```

## ğŸ§ª Testing

### Basic Tests
```bash
python test_components.py
```

Tests:
- âœ“ Module imports
- âœ“ Configuration
- âœ“ Audio devices
- âœ“ Memory system
- âœ“ API connections (basic)

### Full API Tests
```bash
python test_components.py --full-test
```

âš ï¸ **Warning**: Uses API credits

## ğŸ’¡ Usage Tips

### Best Practices
1. **Short responses**: Ask for brief answers for faster playback
2. **Natural speech**: Speak naturally, the system handles it
3. **Interruptions**: Don't hesitate to interrupt if needed
4. **Context**: Reference earlier topics - memory persists

### Example Conversations

**Simple query**:
```
You: "What's the weather like today?"
Assistant: "I don't have access to real-time weather data..."
```

**With context**:
```
You: "Tell me about Python"
Assistant: "Python is a high-level programming language..."

[Later]
You: "What are some good libraries for that?"
Assistant: "For Python, some popular libraries are..."
```

**Interruption**:
```
Assistant: "Python was created by Guido van Rossum in 1991..."
[You press SPACE]
Assistant: [Stops immediately]
You: "Actually, tell me about JavaScript instead"
```

## ğŸ› Troubleshooting

### No audio input/output
```bash
# Test audio devices
python -c "import sounddevice; print(sounddevice.query_devices())"
```

### API errors
- Check `.env` file has valid API keys
- Verify keys at:
  - Anthropic: https://console.anthropic.com/
  - OpenAI: https://platform.openai.com/api-keys

### Memory not persisting
- Check `conversation_memory.json` exists
- Verify write permissions in directory

### Slow responses
- Check internet connection
- Try shorter prompts
- Reduce `MAX_TOKENS` in config

## ğŸ”’ Privacy & Security

- **API Keys**: Never commit `.env` to version control
- **Conversation Data**: Stored locally in `conversation_memory.json`
- **Audio**: Not stored - processed in memory only
- **API Calls**: Sent to Anthropic and OpenAI servers

## ğŸ¯ What Makes This Impressive

### Technical Excellence

1. **True Streaming**
   - Token-level streaming from Claude
   - Sentence-level TTS synthesis
   - Parallel processing pipeline

2. **Intelligent Interruption**
   - Immediate response to user input
   - Clean state management
   - Context preservation

3. **Memory Architecture**
   - Two-tier memory system
   - Automatic summarization
   - Persistent storage
   - Efficient context retrieval

4. **Production-Ready**
   - Error handling
   - Resource cleanup
   - Logging system
   - Configuration management

### User Experience

- **Natural**: Feels like talking to a person
- **Responsive**: No artificial delays
- **Smart**: Remembers previous conversations
- **Reliable**: Handles edge cases gracefully

## ğŸ“š API Documentation

### Memory Manager

```python
memory = ConversationMemory()

# Add messages
memory.add_message("user", "Hello")
memory.add_message("assistant", "Hi there!")

# Get context for LLM
messages = memory.get_messages_for_llm()
context = memory.get_long_term_context()
```

### LLM Handler

```python
llm = LLMHandler()

# Streaming response
for token in llm.generate_response_streaming(messages, context):
    print(token, end='', flush=True)

# Generate summary
summary = llm.generate_summary(messages)
```

### Audio Components

```python
# Input
audio_input = AudioInput()
audio_input.start_recording()
audio_data = audio_input.stop_recording()

# Output
audio_output = AudioOutput()
audio_output.play_audio(audio_bytes)
audio_output.stop()  # Interrupt
```

## ğŸš€ Future Enhancements

### Planned Features
- [ ] Voice Activity Detection for hands-free operation
- [ ] Multi-language support
- [ ] Custom wake word
- [ ] Conversation export
- [ ] Emotion detection in voice
- [ ] Background noise cancellation
- [ ] Mobile app version

### Performance Improvements
- [ ] Optimize memory usage
- [ ] Cache common responses
- [ ] Parallel TTS synthesis
- [ ] WebSocket streaming

## ğŸ“„ License

MIT License - See LICENSE file for details

## ğŸ¤ Contributing

Contributions welcome! Areas for improvement:
- Voice activity detection
- Better interrupt detection
- Memory optimization
- UI improvements
- Documentation

## ğŸ“ Support

For issues or questions:
1. Check troubleshooting section
2. Review test output
3. Check API status pages
4. Open an issue on GitHub


## ğŸŒŸ Milestone Achievement

You can now:
âœ… Have a conversation with an AI assistant
âœ… Interrupt it mid-sentence
âœ… Have it remember context tomorrow
